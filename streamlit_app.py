#!/usr/bin/env python3
"""
å¤§å­¦å…¥è©¦è‹±å˜èªåˆ†æ Streamlit ã‚¢ãƒ—ãƒª
OCRå‡¦ç†çµæœã®å¯è¦–åŒ–ãƒ»æ¯”è¼ƒåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from utils.data_loader import (
    load_analysis_data, 
    load_university_metadata,
    get_university_list,
    get_vocabulary_list,
    create_university_dataframe,
    create_vocabulary_dataframe,
    calculate_summary_stats
)
from utils.visualizations import (
    create_coverage_radar_chart,
    create_vocabulary_comparison_bar,
    create_university_heatmap,
    create_scatter_coverage_precision,
    create_ocr_confidence_gauge,
    create_performance_metrics_table
)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å¤§å­¦å…¥è©¦è‹±å˜èªåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2E86AB;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = load_analysis_data()
    metadata = load_university_metadata()
    
    if not data:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown('<div class="main-header">ğŸ“š å¤§å­¦å…¥è©¦è‹±å˜èªåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</div>', unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    setup_sidebar(data, metadata)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if st.session_state.get('page', 'overview') == 'overview':
        show_overview_page(data, metadata)
    elif st.session_state.get('page') == 'university':
        show_university_page(data, metadata)
    elif st.session_state.get('page') == 'comparison':
        show_comparison_page(data, metadata)

def setup_sidebar(data: dict, metadata: dict):
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
    st.sidebar.title("ğŸ“Š ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # ãƒšãƒ¼ã‚¸é¸æŠ
    page = st.sidebar.radio(
        "ãƒšãƒ¼ã‚¸ã‚’é¸æŠ",
        ["overview", "university", "comparison"],
        format_func=lambda x: {
            "overview": "ğŸ  æ¦‚è¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
            "university": "ğŸ« å¤§å­¦åˆ¥è©³ç´°",
            "comparison": "âš–ï¸ æ¯”è¼ƒåˆ†æ"
        }[x]
    )
    st.session_state.page = page
    
    st.sidebar.markdown("---")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.sidebar.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    
    # ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡é–¾å€¤ï¼ˆå…ˆã«è¨­å®šï¼‰
    min_coverage = st.sidebar.slider(
        "æœ€å°ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ (%)",
        min_value=0.0,
        max_value=50.0,
        value=0.0,
        step=1.0,
        help="ã“ã®å€¤ã‚ˆã‚Šä½ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã®å¤§å­¦ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“"
    )
    st.session_state.min_coverage = min_coverage
    
    # éšå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.sidebar.subheader("ğŸ“Š è¡¨ç¤ºãƒ¬ãƒ™ãƒ«")
    display_mode = st.sidebar.radio(
        "é¸æŠãƒ¢ãƒ¼ãƒ‰",
        ["å¤§å­¦ãƒ¬ãƒ™ãƒ«ï¼ˆçµ±åˆï¼‰", "å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ï¼ˆè©³ç´°ï¼‰", "æ··åˆé¸æŠ"],
        help="å¤§å­¦ãƒ¬ãƒ™ãƒ«ï¼šçµ±åˆãƒ‡ãƒ¼ã‚¿+å˜ä¸€å¤§å­¦ã€å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ï¼šå­¦éƒ¨åˆ¥ãƒ‡ãƒ¼ã‚¿ã€æ··åˆï¼šå…¨ã¦è‡ªç”±é¸æŠ"
    )
    
    # å¤§å­¦é¸æŠ
    all_universities = get_university_list(data)
    if not all_universities:
        st.sidebar.error("å¤§å­¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        st.sidebar.write("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:", list(data.keys()))
        return
    
    # é¸æŠãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦é¸æŠè‚¢ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if display_mode == "å¤§å­¦ãƒ¬ãƒ™ãƒ«ï¼ˆçµ±åˆï¼‰":
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ + å˜ä¸€å¤§å­¦ãƒ‡ãƒ¼ã‚¿ï¼ˆå­¦éƒ¨ãŒè¤‡æ•°ãªã„å¤§å­¦ï¼‰ã‚’è¡¨ç¤º
        universities = []
        for univ in all_universities:
            if "ï¼ˆå…¨å­¦éƒ¨ï¼‰" in univ:
                # çµ±åˆãƒ‡ãƒ¼ã‚¿ã¯å«ã‚ã‚‹
                universities.append(univ)
            elif "_" not in univ:
                # å­¦éƒ¨ãŒåˆ†ã‹ã‚Œã¦ã„ãªã„å˜ä¸€å¤§å­¦ï¼ˆæ±äº¬å¤§å­¦ãªã©ï¼‰ã‚‚å«ã‚ã‚‹
                universities.append(univ)
        help_text = "å¤§å­¦ãƒ¬ãƒ™ãƒ«ã§ã®æ¯”è¼ƒï¼ˆçµ±åˆãƒ‡ãƒ¼ã‚¿ + å˜ä¸€å¤§å­¦ï¼‰"
    elif display_mode == "å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ï¼ˆè©³ç´°ï¼‰":
        # å­¦éƒ¨åˆ¥ãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤ºï¼ˆçµ±åˆãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–ï¼‰
        universities = [univ for univ in all_universities if "ï¼ˆå…¨å­¦éƒ¨ï¼‰" not in univ]
        help_text = "å­¦éƒ¨åˆ¥ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒ"
    else:  # æ··åˆé¸æŠ
        # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        universities = all_universities
        help_text = "å¤§å­¦çµ±åˆãƒ‡ãƒ¼ã‚¿ã¨å­¦éƒ¨åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªç”±ã«çµ„ã¿åˆã‚ã›ã¦æ¯”è¼ƒ"
    
    # ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨
    if min_coverage > 0:
        from utils.data_loader import filter_universities_by_criteria
        universities = [univ for univ in universities if univ in filter_universities_by_criteria(data, min_coverage)]
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
    mode_label = {"å¤§å­¦ãƒ¬ãƒ™ãƒ«ï¼ˆçµ±åˆï¼‰": "å¤§å­¦", "å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ï¼ˆè©³ç´°ï¼‰": "å­¦éƒ¨", "æ··åˆé¸æŠ": "å…¨ã¦"}[display_mode]
    st.sidebar.write(f"{mode_label}: {len(universities)} | å…¨ä½“: {len(all_universities)}")
    if min_coverage > 0:
        st.sidebar.write(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶: ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ â‰¥ {min_coverage}%")
    
    selected_universities = st.sidebar.multiselect(
        "ğŸ« å¤§å­¦ãƒ»å­¦éƒ¨ã‚’é¸æŠ",
        universities,
        default=[],
        help=help_text
    )
    st.session_state.selected_universities = selected_universities
    
    # å˜èªå¸³é¸æŠ
    vocabularies = get_vocabulary_list(data)
    selected_vocabularies = st.sidebar.multiselect(
        "å˜èªå¸³ã‚’é¸æŠ",
        vocabularies,
        default=vocabularies
    )
    st.session_state.selected_vocabularies = selected_vocabularies
    
    st.sidebar.markdown("---")
    
    # ç°¡æ½”ãªæŒ‡æ¨™èª¬æ˜
    st.sidebar.subheader("ğŸ’¡ æŒ‡æ¨™ã®æ„å‘³")
    st.sidebar.markdown("""
    **ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡**: å˜èªå¸³ã®ä½•%ãŒå…¥è©¦ã«å‡ºç¾
    
    **æŠ½å‡ºç²¾åº¦**: å­¦ç¿’èªå½™ã®ä½•%ãŒå…¥è©¦ã«å‡ºç¾
    
    **ä¸€è‡´èªæ•°**: å®Ÿéš›ã«ä¸€è‡´ã—ãŸèªæ•°
    """)
    
    # ä½ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã®èª¬æ˜
    if min_coverage == 0:
        st.sidebar.info("""
        ğŸ“Œ **æ³¨æ„**: ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã¯å¤§å­¦ãƒ»å­¦éƒ¨ã«ã‚ˆã‚Š9.6-16.9%ã®ç¯„å›²ã§å¤‰å‹•ã—ã¾ã™ã€‚
        ã“ã‚Œã¯å‡ºé¡Œå‚¾å‘ã‚„å•é¡Œå½¢å¼ã®é•ã„ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚
        """)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¤§å­¦ã¸ã®èª¬æ˜
    if len(universities) < len(all_universities):
        hidden_count = len(all_universities) - len(universities)
        st.sidebar.warning(f"""
        âš ï¸ {hidden_count}å¤§å­¦ãŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§éè¡¨ç¤ºã§ã™ã€‚
        ã™ã¹ã¦ã®å¤§å­¦ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã‚’0%ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚
        """)
    
    st.sidebar.markdown("---")
    
    # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
    st.sidebar.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
    overall_summary = data.get('overall_summary', {})
    st.sidebar.write(f"**åˆ†ææ—¥æ™‚**: {overall_summary.get('analysis_timestamp', 'N/A')[:10]}")
    st.sidebar.write(f"**å¤§å­¦æ•°**: {len(universities)}")
    st.sidebar.write(f"**å˜èªå¸³æ•°**: {len(vocabularies)}")
    st.sidebar.write(f"**ç·å˜èªæ•°**: {overall_summary.get('total_words_extracted', 0):,}")

def show_overview_page(data: dict, metadata: dict):
    """æ¦‚è¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸"""
    st.markdown('<div class="sub-header">ğŸ  æ¦‚è¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</div>', unsafe_allow_html=True)
    
    # ç°¡æ½”ãªå®šç¾©ï¼ˆå¸¸æ™‚è¡¨ç¤ºï¼‰
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
        **ğŸ“ˆ ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã¨ã¯ï¼Ÿ**  
        å˜èªå¸³ã®ä½•%ã®èªå½™ãŒå®Ÿéš›ã®å…¥è©¦å•é¡Œã«å‡ºç¾ã—ãŸã‹ã‚’ç¤ºã™æŒ‡æ¨™ã€‚é«˜ã„ã»ã©å®Ÿç”¨çš„ã€‚
        """)
    
    with col2:
        st.info("""
        **ğŸ¯ æŠ½å‡ºç²¾åº¦ã¨ã¯ï¼Ÿ**  
        æŠ½å‡ºã—ãŸå˜èªã®ã†ã¡ã€å˜èªå¸³ã«å«ã¾ã‚Œã‚‹å‰²åˆã€‚é«˜ã„ã»ã©å­¦ç¿’åŠ¹ç‡ãŒè‰¯ã„ã€‚
        """)
    
    # è©³ç´°ãªæŒ‡æ¨™ã®èª¬æ˜
    with st.expander("ğŸ“– è©³ã—ã„æŒ‡æ¨™ã®æ„å‘³ã‚’ç¢ºèªã™ã‚‹", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ğŸ“ˆ **ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ (Coverage Rate)**
            **å®šç¾©**: å˜èªå¸³ã®ä½•%ã®èªå½™ãŒå®Ÿéš›ã®å…¥è©¦å•é¡Œã«å‡ºç¾ã—ãŸã‹
            
            **è¨ˆç®—å¼**: `ä¸€è‡´èªæ•° Ã· å˜èªå¸³ç·èªæ•° Ã— 100`
            
            **ä¾‹**: Target 1900ã®24.25% = 460èª Ã· 1,897èª Ã— 100
            
            **æ„å‘³**: ãã®å˜èªå¸³ã®**å®Ÿç”¨æ€§ãƒ»å…¥è©¦é©åˆåº¦**ã‚’è¡¨ã™
            - é«˜ã„ã»ã©å…¥è©¦ã§é »å‡ºã™ã‚‹èªå½™ã‚’å¤šãå«ã‚€
            - å—é¨“å¯¾ç­–ã§ã®åŠ¹ç‡æ€§ã®æŒ‡æ¨™
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ¯ **æŠ½å‡ºç²¾åº¦ (Extraction Precision)**
            **å®šç¾©**: æŠ½å‡ºã—ãŸå˜èªã®ã†ã¡ã€å˜èªå¸³ã«å«ã¾ã‚Œã‚‹å‰²åˆ
            
            **è¨ˆç®—å¼**: `ä¸€è‡´èªæ•° Ã· æŠ½å‡ºãƒ¦ãƒ‹ãƒ¼ã‚¯èªæ•° Ã— 100`
            
            **ä¾‹**: Target 1900ã®26.96% = 460èª Ã· 1,706èª Ã— 100
            
            **æ„å‘³**: ãã®å˜èªå¸³ã§å­¦ç¿’ã™ã‚‹**åŠ¹ç‡æ€§**ã‚’è¡¨ã™
            - é«˜ã„ã»ã©å­¦ã‚“ã å˜èªãŒå…¥è©¦ã«å‡ºã‚„ã™ã„
            - å­¦ç¿’æŠ•è³‡å¯¾åŠ¹æœã®æŒ‡æ¨™
            """)
        
        st.info("""
        ğŸ’¡ **ç†æƒ³çš„ãªå˜èªå¸³**: é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ + é«˜æŠ½å‡ºç²¾åº¦ = åŠ¹ç‡çš„ãªå—é¨“å¯¾ç­–
        """)
    
    st.markdown("---")
    
    # å¤§å­¦é¸æŠçŠ¶æ³ã‚’ç¢ºèª
    selected_universities = st.session_state.get('selected_universities', [])
    
    if not selected_universities:
        # å¤§å­¦ãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆ
        st.info("""
        ğŸ‘ˆ **å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å¤§å­¦ãƒ»å­¦éƒ¨ã‚’é¸æŠã—ã¦ãã ã•ã„**
        
        é¸æŠã—ãŸå¤§å­¦ãƒ»å­¦éƒ¨ã®èªå½™åˆ†æçµæœã¨ãƒãƒ£ãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
        
        - è¤‡æ•°ã®å¤§å­¦ãƒ»å­¦éƒ¨ã‚’é¸æŠã—ã¦æ¯”è¼ƒåˆ†æã‚‚å¯èƒ½ã§ã™
        - ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã®é–¾å€¤è¨­å®šã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚‚ã§ãã¾ã™
        """)
        return
    
    # é¸æŠã•ã‚ŒãŸå¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã‚µãƒãƒªãƒ¼çµ±è¨ˆã‚’è¨ˆç®—
    filtered_data = {
        'university_analysis': {k: v for k, v in data.get('university_analysis', {}).items() if k in selected_universities},
        'vocabulary_summary': data.get('vocabulary_summary', {}),
        'overall_summary': data.get('overall_summary', {})
    }
    summary_stats = calculate_summary_stats(filtered_data)
    
    # é¸æŠã•ã‚ŒãŸå¤§å­¦ã®çµ±è¨ˆ
    selected_total_words = sum([info.get('total_words', 0) for univ, info in data.get('university_analysis', {}).items() if univ in selected_universities])
    selected_total_pages = sum([info.get('pages_processed', 0) for univ, info in data.get('university_analysis', {}).items() if univ in selected_universities])
    selected_avg_confidence = sum([info.get('ocr_confidence', 0) for univ, info in data.get('university_analysis', {}).items() if univ in selected_universities]) / len(selected_universities) if selected_universities else 0
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆé¸æŠã•ã‚ŒãŸå¤§å­¦ã®ã¿ï¼‰
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="é¸æŠå¤§å­¦ç·å˜èªæ•°",
            value=f"{selected_total_words:,}",
            delta=f"{len(selected_universities)}å¤§å­¦ãƒ»å­¦éƒ¨"
        )
    
    with col2:
        st.metric(
            label="å¹³å‡OCRä¿¡é ¼åº¦",
            value=f"{selected_avg_confidence:.1f}%",
            delta=None
        )
    
    with col3:
        st.metric(
            label="æœ€é©å˜èªå¸³",
            value=summary_stats.get('best_vocabulary', 'N/A'),
            delta=f"{summary_stats.get('best_coverage_rate', 0):.1f}%"
        )
    
    with col4:
        st.metric(
            label="å‡¦ç†ãƒšãƒ¼ã‚¸æ•°",
            value=f"{selected_total_pages}",
            delta=None
        )
    
    st.markdown("---")
    
    # ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºï¼ˆé¸æŠã•ã‚ŒãŸå¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š é¸æŠå¤§å­¦ã®å˜èªå¸³åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãƒ»æŠ½å‡ºç²¾åº¦")
        fig_vocab = create_vocabulary_comparison_bar(filtered_data)
        st.plotly_chart(fig_vocab, use_container_width=True)
        st.caption("ğŸ’¡ é¸æŠã—ãŸå¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãçµ±è¨ˆã€‚ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãŒé«˜ã„ã»ã©å®Ÿç”¨çš„ã€æŠ½å‡ºç²¾åº¦ãŒé«˜ã„ã»ã©å­¦ç¿’åŠ¹ç‡ãŒè‰¯ã„")
    
    with col2:
        st.subheader("ğŸ¯ é¸æŠå¤§å­¦ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ vs æŠ½å‡ºç²¾åº¦")
        fig_scatter = create_scatter_coverage_precision(filtered_data)
        st.plotly_chart(fig_scatter, use_container_width=True)
        st.caption("ğŸ’¡ é¸æŠã—ãŸå¤§å­¦ã§ã®çµæœã€‚å³ä¸Šã«ã‚ã‚‹å˜èªå¸³ã»ã©ç†æƒ³çš„ï¼ˆé«˜å®Ÿç”¨æ€§Ã—é«˜åŠ¹ç‡æ€§ï¼‰")
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆé¸æŠã•ã‚ŒãŸå¤§å­¦ã®ã¿ï¼‰
    if len(selected_universities) > 1:
        st.subheader("ğŸ”¥ é¸æŠå¤§å­¦Ã—å˜èªå¸³ ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        fig_heatmap = create_university_heatmap(filtered_data)
        st.plotly_chart(fig_heatmap, use_container_width=True)
        st.caption("ğŸ’¡ è‰²ãŒæ¿ƒã„ï¼ˆèµ¤ã„ï¼‰ã»ã©é«˜ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã€‚é¸æŠã—ãŸå¤§å­¦é–“ã§ã®å˜èªå¸³é©åˆåº¦ã‚’æ¯”è¼ƒ")
    else:
        st.subheader("ğŸ“‹ é¸æŠå¤§å­¦ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿")
        st.info("è¤‡æ•°ã®å¤§å­¦ã‚’é¸æŠã™ã‚‹ã¨ã€å¤§å­¦é–“æ¯”è¼ƒã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    
    # æ–‡ç« çµ±è¨ˆï¼ˆé¸æŠã•ã‚ŒãŸå¤§å­¦ã®ã¿ï¼‰
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ é¸æŠå¤§å­¦ã®æ–‡ç« çµ±è¨ˆ")
        
        # é¸æŠã•ã‚ŒãŸå¤§å­¦ã®æ–‡ç« çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        university_data = {k: v for k, v in data.get('university_analysis', {}).items() if k in selected_universities}
        sentence_table_data = []
        
        for univ, info in university_data.items():
            sentence_table_data.append({
                'å¤§å­¦ãƒ»å­¦éƒ¨': univ.replace('æ—©ç¨²ç”°å¤§å­¦_', 'æ—©å¤§_'),
                'æ–‡ã®æ•°': info.get('total_sentences', 0),
                'å¹³å‡èªæ•°/æ–‡': info.get('avg_words_per_sentence', 0.0)
            })
        
        # DataFrameã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆï¼ˆæ–‡ã®æ•°ã®é™é †ï¼‰
        import pandas as pd
        sentence_df = pd.DataFrame(sentence_table_data)
        sentence_df = sentence_df.sort_values('æ–‡ã®æ•°', ascending=False)
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ä»˜ããƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        try:
            st.dataframe(
                sentence_df.style.format({
                    'æ–‡ã®æ•°': '{:,}',
                    'å¹³å‡èªæ•°/æ–‡': '{:.1f}'
                }).background_gradient(subset=['æ–‡ã®æ•°', 'å¹³å‡èªæ•°/æ–‡'], cmap='RdYlGn'),
                use_container_width=True,
                height=400
            )
        except ImportError:
            # matplotlibãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            st.dataframe(
                sentence_df.style.format({
                    'æ–‡ã®æ•°': '{:,}',
                    'å¹³å‡èªæ•°/æ–‡': '{:.1f}'
                }),
                use_container_width=True,
                height=400
            )
        
        st.caption("ğŸ’¡ æ–‡ã®æ•°ãŒå¤šã„ã»ã©è±Šå¯Œãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€å¹³å‡èªæ•°/æ–‡ãŒé«˜ã„ã»ã©è¤‡é›‘ãªæ–‡ç« æ§‹é€ ")
    
    with col2:
        st.subheader("âš¡ OCRå‡¦ç†å“è³ª")
        avg_confidence = summary_stats.get('average_ocr_confidence', 0)
        fig_gauge = create_ocr_confidence_gauge(avg_confidence)
        st.plotly_chart(fig_gauge, use_container_width=True)
        
        # é¸æŠå¤§å­¦ã®æ–‡ç« çµ±è¨ˆã‚µãƒãƒªãƒ¼
        if university_data:
            selected_total_sentences = sum([info.get('total_sentences', 0) for info in university_data.values()])
            selected_total_words_in_sentences = sum([info.get('avg_words_per_sentence', 0) * info.get('total_sentences', 0) for info in university_data.values()])
            selected_overall_avg = selected_total_words_in_sentences / selected_total_sentences if selected_total_sentences > 0 else 0
            
            st.markdown("### ğŸ“Š é¸æŠå¤§å­¦æ–‡ç« çµ±è¨ˆ")
            st.metric("ç·æ–‡æ•°", f"{selected_total_sentences:,}")
            st.metric("å¹³å‡èªæ•°/æ–‡", f"{selected_overall_avg:.1f}èª")

def show_university_page(data: dict, metadata: dict):
    """å¤§å­¦åˆ¥è©³ç´°ãƒšãƒ¼ã‚¸"""
    st.markdown('<div class="sub-header">ğŸ« å¤§å­¦åˆ¥è©³ç´°åˆ†æ</div>', unsafe_allow_html=True)
    
    # ç°¡æ½”ãªæŒ‡æ¨™èª¬æ˜
    st.info("""
    ğŸ’¡ **ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡**: å˜èªå¸³ã®ä½•%ãŒå…¥è©¦ã«å‡ºç¾ | **æŠ½å‡ºç²¾åº¦**: å­¦ç¿’ã—ãŸèªå½™ã®ä½•%ãŒå…¥è©¦ã«å‡ºç¾ | è©³ç´°ã¯æ¦‚è¦ãƒšãƒ¼ã‚¸ã§ç¢ºèª
    """)
    
    # å¤§å­¦é¸æŠ
    universities = get_university_list(data)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
    st.write(f"ãƒ‡ãƒãƒƒã‚°: åˆ©ç”¨å¯èƒ½ãªå¤§å­¦æ•° = {len(universities)}")
    if universities:
        st.write("åˆ©ç”¨å¯èƒ½ãªå¤§å­¦ä¾‹:", universities[:3])
    
    if not universities:
        st.error("å¤§å­¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    selected_university = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹å¤§å­¦ãƒ»å­¦éƒ¨ã‚’é¸æŠ", universities)
    
    if not selected_university:
        st.warning("å¤§å­¦ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    university_data = data.get('university_analysis', {}).get(selected_university, {})
    university_meta = metadata.get('universities', {}).get(selected_university, {})
    
    # å¤§å­¦æƒ…å ±ã‚«ãƒ¼ãƒ‰
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info(f"""
        **ğŸ« {university_meta.get('full_name', selected_university)}**
        - åˆ†é¡: {university_meta.get('category', 'N/A')}
        - åœ°åŸŸ: {university_meta.get('region', 'N/A')}
        """)
    
    with col2:
        st.info(f"""
        **ğŸ“Š å‡¦ç†çµ±è¨ˆ**
        - ç·å˜èªæ•°: {university_data.get('total_words', 0):,}
        - ãƒ¦ãƒ‹ãƒ¼ã‚¯èªæ•°: {university_data.get('unique_words', 0):,}
        - æ–‡ã®æ•°: {university_data.get('total_sentences', 0):,}
        - å¹³å‡èªæ•°/æ–‡: {university_data.get('avg_words_per_sentence', 0):.1f}èª
        - å‡¦ç†ãƒšãƒ¼ã‚¸: {university_data.get('pages_processed', 0)}
        """)
    
    with col3:
        ocr_confidence = university_data.get('ocr_confidence', 0)
        confidence_color = "ğŸŸ¢" if ocr_confidence >= 95 else "ğŸŸ¡" if ocr_confidence >= 90 else "ğŸ”´"
        st.info(f"""
        **âš¡ OCRå“è³ª**
        - ä¿¡é ¼åº¦: {confidence_color} {ocr_confidence:.1f}%
        - ãƒ•ã‚¡ã‚¤ãƒ«: {university_data.get('source_file', 'N/A').split('/')[-1]}
        """)
    
    st.markdown("---")
    
    # å˜èªå¸³åˆ¥è©³ç´°
    st.subheader("ğŸ“š å˜èªå¸³åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
    
    vocab_coverage = university_data.get('vocabulary_coverage', {})
    vocab_df_data = []
    
    for vocab_name, vocab_stats in vocab_coverage.items():
        vocab_df_data.append({
            'å˜èªå¸³': vocab_name,
            'ä¸€è‡´èªæ•°': vocab_stats.get('matched_words_count', 0),
            'ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)': round(vocab_stats.get('target_coverage_rate', 0), 1),
            'æŠ½å‡ºç²¾åº¦(%)': round(vocab_stats.get('extraction_precision', 0), 1)
        })
    
    vocab_df = pd.DataFrame(vocab_df_data)
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ä»˜ããƒ†ãƒ¼ãƒ–ãƒ«
    try:
        st.dataframe(
            vocab_df.style.format({
                'ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)': '{:.1f}',
                'æŠ½å‡ºç²¾åº¦(%)': '{:.1f}'
            }).background_gradient(subset=['ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)', 'æŠ½å‡ºç²¾åº¦(%)'], cmap='RdYlGn'),
            use_container_width=True
        )
    except ImportError:
        # matplotlibãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.dataframe(
            vocab_df.style.format({
                'ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)': '{:.1f}',
                'æŠ½å‡ºç²¾åº¦(%)': '{:.1f}'
            }),
            use_container_width=True
        )
    
    # å˜èªå¸³æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ
    if len(vocab_df_data) > 1:
        col1, col2 = st.columns(2)
        
        with col1:
            fig_coverage = px.bar(
                vocab_df, 
                x='å˜èªå¸³', 
                y='ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)',
                title='å˜èªå¸³åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡',
                color='ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)',
                color_continuous_scale='RdYlGn'
            )
            fig_coverage.update_layout(height=400)
            st.plotly_chart(fig_coverage, use_container_width=True)
        
        with col2:
            fig_precision = px.bar(
                vocab_df, 
                x='å˜èªå¸³', 
                y='æŠ½å‡ºç²¾åº¦(%)',
                title='å˜èªå¸³åˆ¥æŠ½å‡ºç²¾åº¦',
                color='æŠ½å‡ºç²¾åº¦(%)',
                color_continuous_scale='RdYlBu'
            )
            fig_precision.update_layout(height=400)
            st.plotly_chart(fig_precision, use_container_width=True)

def show_comparison_page(data: dict, metadata: dict):
    """æ¯”è¼ƒåˆ†æãƒšãƒ¼ã‚¸"""
    st.markdown('<div class="sub-header">âš–ï¸ æ¯”è¼ƒåˆ†æ</div>', unsafe_allow_html=True)
    
    # ç°¡æ½”ãªæŒ‡æ¨™èª¬æ˜
    st.info("""
    ğŸ“Š **ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡**: å˜èªå¸³ã®å®Ÿç”¨æ€§ï¼ˆé«˜ã„ã»ã©å…¥è©¦é »å‡ºèªã‚’å¤šãå«ã‚€ï¼‰ | **æŠ½å‡ºç²¾åº¦**: å­¦ç¿’åŠ¹ç‡æ€§ï¼ˆé«˜ã„ã»ã©å­¦ç¿’åŠ¹æœå¤§ï¼‰
    """)
    
    # æ¯”è¼ƒå¯¾è±¡é¸æŠ
    universities = get_university_list(data)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    st.write(f"ãƒ‡ãƒãƒƒã‚°: åˆ©ç”¨å¯èƒ½ãªå¤§å­¦æ•° = {len(universities)}")
    if universities:
        st.write("åˆ©ç”¨å¯èƒ½ãªå¤§å­¦:", universities[:5])  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
    
    selected_universities = st.multiselect(
        "æ¯”è¼ƒã™ã‚‹å¤§å­¦ãƒ»å­¦éƒ¨ã‚’é¸æŠï¼ˆ2ã¤ä»¥ä¸Šï¼‰",
        universities,
        default=universities[:3] if len(universities) >= 3 else universities
    )
    
    if len(selected_universities) < 2:
        st.warning("æ¯”è¼ƒã«ã¯2ã¤ä»¥ä¸Šã®å¤§å­¦ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return
    
    # æ¯”è¼ƒåˆ†æã‚¿ãƒ–
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ", "ğŸ“‹ è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«", "ğŸ¯ ãƒ©ãƒ³ã‚­ãƒ³ã‚°"])
    
    with tab1:
        st.subheader("ğŸ•¸ï¸ å¤§å­¦åˆ¥å˜èªå¸³ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ")
        fig_radar = create_coverage_radar_chart(data, selected_universities)
        st.plotly_chart(fig_radar, use_container_width=True)
        
        st.info("""
        **ğŸ“– èª­ã¿æ–¹**: 
        - å¤–å´ã«å‘ã‹ã†ã»ã©é«˜ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ï¼ˆãã®å˜èªå¸³ãŒå…¥è©¦ã«ã‚ˆã‚Šé©ã—ã¦ã„ã‚‹ï¼‰
        - å„è»¸ã¯å˜èªå¸³ã‚’è¡¨ã™ï¼ˆ5ç¨®é¡ã®å˜èªå¸³ã‚’æ¯”è¼ƒï¼‰
        - è‰²åˆ†ã‘ã§å¤§å­¦ã‚’åŒºåˆ¥ï¼ˆè¤‡æ•°å¤§å­¦ã®ç‰¹å¾´ã‚’ä¸€ç›®ã§æ¯”è¼ƒï¼‰
        - å¤§ããå¤–ã«åºƒãŒã£ãŸå½¢ã»ã©ã€å¤šãã®å˜èªå¸³ã§é«˜ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ã‚’ç¤ºã™
        """)
    
    with tab2:
        st.subheader("ğŸ“Š å¤§å­¦åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«")
        performance_df = create_performance_metrics_table(data, selected_universities)
        
        try:
            st.dataframe(
                performance_df.style.format({
                    'OCRä¿¡é ¼åº¦(%)': '{:.1f}',
                    'æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)': '{:.1f}'
                }).background_gradient(
                    subset=['OCRä¿¡é ¼åº¦(%)', 'æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)'], 
                    cmap='RdYlGn'
                ),
                use_container_width=True
            )
        except ImportError:
            # matplotlibãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            st.dataframe(
                performance_df.style.format({
                    'OCRä¿¡é ¼åº¦(%)': '{:.1f}',
                    'æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)': '{:.1f}'
                }),
                use_container_width=True
            )
    
    with tab3:
        st.subheader("ğŸ† å¤§å­¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–é¸æŠ
        ranking_criteria = st.selectbox(
            "ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–ã‚’é¸æŠ",
            ["æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡", "OCRä¿¡é ¼åº¦", "ç·å˜èªæ•°", "ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°"]
        )
        
        performance_df = create_performance_metrics_table(data, selected_universities)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ¬ç•ªã§ã¯å‰Šé™¤å¯èƒ½ï¼‰
        # st.write("DEBUG - DataFrame columns:", performance_df.columns.tolist())
        
        try:
            if ranking_criteria == "æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡":
                sorted_df = performance_df.sort_values('æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)', ascending=False)
            elif ranking_criteria == "OCRä¿¡é ¼åº¦":
                sorted_df = performance_df.sort_values('OCRä¿¡é ¼åº¦(%)', ascending=False)
            elif ranking_criteria == "ç·å˜èªæ•°":
                sorted_df = performance_df.sort_values('ç·å˜èªæ•°', ascending=False)
            else:  # ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°
                sorted_df = performance_df.sort_values('ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°', ascending=False)
        except KeyError as e:
            st.error(f"ã‚½ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: åˆ— '{e}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {performance_df.columns.tolist()}")
            sorted_df = performance_df
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        for i, (_, row) in enumerate(sorted_df.iterrows(), 1):
            medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}ä½"
            
            # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°
            column_mapping = {
                "æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡": "æœ€é«˜ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡(%)",
                "OCRä¿¡é ¼åº¦": "OCRä¿¡é ¼åº¦(%)",
                "ç·å˜èªæ•°": "ç·å˜èªæ•°",
                "ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°": "ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°"
            }
            
            actual_column = column_mapping.get(ranking_criteria, ranking_criteria)
            
            try:
                criteria_value = row[actual_column]
                
                # å€¤ã®è¡¨ç¤ºå½¢å¼ã‚’èª¿æ•´
                if "%" in actual_column:
                    criteria_display = f"{criteria_value}%"
                else:
                    criteria_display = f"{criteria_value:,}"
                
                with st.container():
                    st.markdown(f"""
                    ### {medal} {row['å¤§å­¦ãƒ»å­¦éƒ¨']}
                    - **{ranking_criteria}**: {criteria_display}
                    - **æœ€é©å˜èªå¸³**: {row['æœ€é©å˜èªå¸³']}
                    - **OCRä¿¡é ¼åº¦**: {row['OCRä¿¡é ¼åº¦(%)']}%
                    """)
            except KeyError as e:
                st.error(f"è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: åˆ— '{e}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                with st.container():
                    st.markdown(f"""
                    ### {medal} {row['å¤§å­¦ãƒ»å­¦éƒ¨']}
                    - **æœ€é©å˜èªå¸³**: {row.get('æœ€é©å˜èªå¸³', 'N/A')}
                    - **OCRä¿¡é ¼åº¦**: {row.get('OCRä¿¡é ¼åº¦(%)', 0)}%
                    """)

if __name__ == "__main__":
    main()