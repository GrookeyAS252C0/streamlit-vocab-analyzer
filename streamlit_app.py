#!/usr/bin/env python3
"""
ReadingAssist Analyzer - Simple Streamlit Web Application
æœ€å°é™ã®ä¾å­˜é–¢ä¿‚ã§å‹•ä½œã™ã‚‹è»½é‡ç‰ˆ
"""

import streamlit as st
import pandas as pd
import json
import re
from pathlib import Path

# Streamlitè¨­å®š
st.set_page_config(
    page_title="ReadingAssist Analyzer",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #4CAF50 0%, #45a049 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4CAF50;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

def simple_word_analysis(text):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªå˜èªåˆ†æ"""
    # åŸºæœ¬çš„ãªå˜èªæŠ½å‡º
    words = re.findall(r'\b[a-zA-Z]{3,}\b', text.lower())
    unique_words = set(words)
    
    # åŸºæœ¬çµ±è¨ˆ
    total_words = len(words)
    unique_word_count = len(unique_words)
    
    # æ–‡æ•°è¨ˆç®—
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    sentence_count = len(sentences)
    
    # å¹³å‡æ–‡é•·
    avg_sentence_length = total_words / sentence_count if sentence_count > 0 else 0
    
    # å˜èªé »åº¦
    word_freq = {}
    for word in words:
        word_freq[word] = word_freq.get(word, 0) + 1
    
    # ä¸Šä½é »å‡ºå˜èª
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    
    return {
        'total_words': total_words,
        'unique_words': unique_word_count,
        'sentences': sentence_count,
        'avg_sentence_length': avg_sentence_length,
        'top_words': top_words,
        'vocabulary_diversity': unique_word_count / total_words if total_words > 0 else 0
    }

def estimate_difficulty(analysis):
    """é›£æ˜“åº¦æ¨å®š"""
    avg_length = analysis['avg_sentence_length']
    diversity = analysis['vocabulary_diversity']
    
    # ç°¡æ˜“é›£æ˜“åº¦åˆ¤å®š
    if avg_length < 10 and diversity > 0.7:
        return "æ˜“", 30
    elif avg_length < 15 and diversity > 0.5:
        return "ã‚„ã‚„æ˜“", 45
    elif avg_length < 20 and diversity > 0.4:
        return "ä¸­", 60
    elif avg_length < 25 and diversity > 0.3:
        return "ã‚„ã‚„é›£", 75
    else:
        return "é›£", 90

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“š ReadingAssist Analyzer</h1>
        <p>è‹±æ–‡èª­è§£åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆè»½é‡ç‰ˆï¼‰</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ“‹ åˆ†æè¨­å®š")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        input_method = st.radio(
            "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
            ["ãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›", "ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ"]
        )
        
        if input_method == "ãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›":
            user_text = st.text_area(
                "åˆ†æã—ãŸã„è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                height=200,
                placeholder="Enter English text here..."
            )
        else:
            sample_texts = {
                "å­¦è¡“æ–‡ç« ": """
                The development of artificial intelligence has revolutionized numerous industries. 
                Machine learning algorithms can now process vast amounts of data to identify patterns 
                and make predictions with remarkable accuracy. However, the implementation of these 
                technologies requires careful consideration of ethical implications and potential 
                societal impacts.
                """,
                "ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹": """
                Scientists have made a breakthrough in renewable energy technology. The new solar 
                panels demonstrate significantly improved efficiency rates compared to traditional 
                models. This advancement could accelerate the global transition to sustainable 
                energy sources and reduce dependence on fossil fuels.
                """,
                "å°èª¬": """
                The old lighthouse stood silently against the stormy sky. Sarah walked slowly 
                along the rocky shore, remembering the stories her grandmother used to tell. 
                The waves crashed violently against the cliffs, creating a symphony of natural 
                sounds that seemed to echo her inner thoughts.
                """
            }
            
            selected_sample = st.selectbox("ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ", list(sample_texts.keys()))
            user_text = sample_texts[selected_sample].strip()
            st.text_area("é¸æŠã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ", value=user_text, height=150, disabled=True)
        
        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
        analyze_button = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", type="primary", use_container_width=True)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if analyze_button and user_text.strip():
        # åˆ†æå®Ÿè¡Œ
        with st.spinner("åˆ†æã‚’å®Ÿè¡Œä¸­..."):
            analysis = simple_word_analysis(user_text)
            difficulty, score = estimate_difficulty(analysis)
        
        st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # çµæœè¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·å˜èªæ•°", f"{analysis['total_words']:,}")
        with col2:
            st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°", f"{analysis['unique_words']:,}")
        with col3:
            st.metric("æ–‡æ•°", analysis['sentences'])
        with col4:
            st.metric("å¹³å‡æ–‡é•·", f"{analysis['avg_sentence_length']:.1f}èª")
        
        # é›£æ˜“åº¦è©•ä¾¡
        st.subheader("ğŸ“Š é›£æ˜“åº¦è©•ä¾¡")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«", difficulty)
        with col2:
            st.metric("é›£æ˜“åº¦ã‚¹ã‚³ã‚¢", f"{score}/100")
        with col3:
            st.metric("èªå½™å¤šæ§˜æ€§", f"{analysis['vocabulary_diversity']:.3f}")
        
        # é »å‡ºå˜èª
        if analysis['top_words']:
            st.subheader("ğŸ”¥ é »å‡ºå˜èª Top 10")
            
            # DataFrameã§è¡¨ç¤º
            word_df = pd.DataFrame(analysis['top_words'], columns=['å˜èª', 'å‡ºç¾å›æ•°'])
            st.dataframe(word_df, use_container_width=True)
        
        # è©³ç´°çµ±è¨ˆ
        with st.expander("ğŸ“‹ è©³ç´°çµ±è¨ˆ"):
            st.json({
                "åŸºæœ¬çµ±è¨ˆ": {
                    "ç·å˜èªæ•°": analysis['total_words'],
                    "ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°": analysis['unique_words'],
                    "æ–‡æ•°": analysis['sentences'],
                    "å¹³å‡æ–‡é•·": round(analysis['avg_sentence_length'], 2)
                },
                "èª­è§£æŒ‡æ¨™": {
                    "èªå½™å¤šæ§˜æ€§": round(analysis['vocabulary_diversity'], 3),
                    "é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«": difficulty,
                    "é›£æ˜“åº¦ã‚¹ã‚³ã‚¢": score
                }
            })
        
        # å­¦ç¿’ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        st.subheader("ğŸ’¡ å­¦ç¿’ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
        
        if score < 40:
            st.info("""
            **åˆç´šãƒ¬ãƒ™ãƒ«**: ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯æ¯”è¼ƒçš„èª­ã¿ã‚„ã™ã„ã§ã™ã€‚
            - åŸºæœ¬çš„ãªæ–‡æ³•æ§‹é€ ã®ç†è§£ã‚’æ·±ã‚ã¾ã—ã‚‡ã†
            - èªå½™åŠ›ã®åŸºç¤å›ºã‚ã‚’ç¶™ç¶šã—ã¾ã—ã‚‡ã†
            """)
        elif score < 70:
            st.warning("""
            **ä¸­ç´šãƒ¬ãƒ™ãƒ«**: é©åº¦ãªæŒ‘æˆ¦ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚
            - è¤‡æ–‡ã®æ§‹é€ ç†è§£ã«å–ã‚Šçµ„ã¿ã¾ã—ã‚‡ã†
            - èªå½™ã®å¿œç”¨åŠ›ã‚’èº«ã«ã¤ã‘ã¾ã—ã‚‡ã†
            """)
        else:
            st.error("""
            **ä¸Šç´šãƒ¬ãƒ™ãƒ«**: é«˜åº¦ãªèª­è§£åŠ›ãŒå¿…è¦ã§ã™ã€‚
            - é«˜åº¦ãªèªå½™ãƒ»è¡¨ç¾ã®ç¿’å¾—ãŒå¿…è¦ã§ã™
            - è¤‡é›‘ãªæ–‡æ§‹é€ ã®åˆ†æç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†
            """)
    
    elif analyze_button:
        st.warning("åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    else:
        # ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒšãƒ¼ã‚¸
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            st.markdown("""
            ### ğŸ¯ ReadingAssist Analyzer ã¸ã‚ˆã†ã“ã
            
            ã“ã®ã‚¢ãƒ—ãƒªã¯è‹±æ–‡ãƒ†ã‚­ã‚¹ãƒˆã®èª­è§£é›£æ˜“åº¦ã‚’åˆ†æã—ã€å­¦ç¿’ã«å½¹ç«‹ã¤æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚
            
            **ğŸ“Š åˆ†ææ©Ÿèƒ½:**
            - èªå½™çµ±è¨ˆï¼ˆå˜èªæ•°ã€èªå½™å¤šæ§˜æ€§ï¼‰
            - æ–‡æ§‹é€ åˆ†æï¼ˆæ–‡æ•°ã€å¹³å‡æ–‡é•·ï¼‰
            - é›£æ˜“åº¦è©•ä¾¡ï¼ˆåˆç´šã€œä¸Šç´šï¼‰
            - é »å‡ºå˜èªãƒ©ãƒ³ã‚­ãƒ³ã‚°
            - å­¦ç¿’ã‚¢ãƒ‰ãƒã‚¤ã‚¹
            
            **ğŸš€ ä½¿ã„æ–¹:**
            å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è‹±æ–‡ã‚’å…¥åŠ›ã—ã€ã€Œåˆ†æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
            """)

if __name__ == "__main__":
    main()