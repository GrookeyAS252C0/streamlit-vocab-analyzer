#!/usr/bin/env python3
"""
PDFå‡¦ç†é€²è¡ŒçŠ¶æ³ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import os
from datetime import datetime

def check_processing_progress():
    """å‡¦ç†é€²è¡ŒçŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
    
    print("ğŸ“Š PDFå‡¦ç†é€²è¡ŒçŠ¶æ³ãƒã‚§ãƒƒã‚¯")
    print("=" * 50)
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    pdf_files = [f for f in os.listdir("PDF/") if f.endswith('.pdf')]
    print(f"ğŸ“ å‡¦ç†å¯¾è±¡PDFãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pdf_files)}")
    
    # æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    result_file = "extraction_results_pure_english.json"
    if os.path.exists(result_file):
        with open(result_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        extracted_data = data.get('extracted_data', [])
        processed_files = len(extracted_data)
        
        print(f"âœ… å‡¦ç†å®Œäº†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {processed_files}/{len(pdf_files)}")
        print(f"ğŸ“ˆ å‡¦ç†é€²æ—: {processed_files/len(pdf_files)*100:.1f}%")
        
        if extracted_data:
            print("\nğŸ¯ å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«:")
            total_words = 0
            total_confidence = 0
            
            for item in extracted_data:
                source_file = item.get('source_file', 'N/A')
                word_count = len(item.get('extracted_words', []))
                confidence = item.get('ocr_confidence', 0)
                pages = item.get('pages_processed', 0)
                
                total_words += word_count
                total_confidence += confidence
                
                print(f"  ğŸ“„ {source_file}")
                print(f"     å˜èªæ•°: {word_count:,}, OCRä¿¡é ¼åº¦: {confidence:.1%}, ãƒšãƒ¼ã‚¸æ•°: {pages}")
            
            if extracted_data:
                avg_confidence = total_confidence / len(extracted_data)
                print(f"\nğŸ“Š çµ±è¨ˆ:")
                print(f"  ç·å˜èªæ•°: {total_words:,}")
                print(f"  å¹³å‡OCRä¿¡é ¼åº¦: {avg_confidence:.1%}")
        
        # æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«
        processed_sources = [item.get('source_file', '') for item in extracted_data]
        pending_files = []
        
        for pdf_file in pdf_files:
            pdf_path = f"PDF/{pdf_file}"
            if pdf_path not in processed_sources:
                pending_files.append(pdf_file)
        
        if pending_files:
            print(f"\nâ³ æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ« ({len(pending_files)}å€‹):")
            for file in pending_files:
                print(f"  ğŸ“„ {file}")
        else:
            print("\nğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†!")
    
    else:
        print("âŒ æŠ½å‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ å‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„: python pdf_text_extractor.py")
    
    print("\n" + "=" * 50)
    print(f"ğŸ• ãƒã‚§ãƒƒã‚¯æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    check_processing_progress()