#!/usr/bin/env python3
"""
ã‚¹ãƒãƒ¼ãƒˆOCRå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
- ã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆæ©Ÿèƒ½
- å¢—åˆ†å‡¦ç†å¯¾å¿œï¼ˆæ–°PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†ï¼‰
- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œãƒ»é€šçŸ¥æ©Ÿèƒ½
- å‡¦ç†çŠ¶æ³ã®è©³ç´°ãƒ­ã‚°
"""

import os
import sys
import json
import subprocess
import platform
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

class SmartOCRProcessor:
    def __init__(self, force_clean: bool = False):
        self.start_time = datetime.now()
        self.force_clean = force_clean
        self.log_file = "smart_processing.log"
        self.progress_file = "smart_progress.json"
        self.processed_files_db = "processed_files.json"
        self.pdf_folder = "PDF"
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«
        self.extraction_results = "extraction_results_pure_english.json"
        self.multi_vocab_results = "multi_vocabulary_analysis_report.json"
        self.vocab_results = "vocabulary_analysis_report.json"
        
    def log(self, message: str, level: str = "INFO"):
        """å¼·åŒ–ã•ã‚ŒãŸãƒ­ã‚°æ©Ÿèƒ½"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {level}: {message}"
        print(log_message)
        
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_message + "\n")
    
    def update_progress(self, step: int, total_steps: int, current_task: str = "", details: str = ""):
        """è©³ç´°é€²æ—æ›´æ–°"""
        progress = {
            "current_step": step,
            "total_steps": total_steps,
            "current_task": current_task,
            "details": details,
            "percentage": round((step / total_steps) * 100, 1),
            "start_time": self.start_time.isoformat(),
            "last_update": datetime.now().isoformat(),
            "force_clean": self.force_clean
        }
        
        with open(self.progress_file, "w", encoding="utf-8") as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
        
        self.log(f"é€²æ—: {step}/{total_steps} ({progress['percentage']}%) - {current_task}")
        if details:
            self.log(f"è©³ç´°: {details}")
    
    def get_file_hash(self, file_path: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œå‡ºç”¨ï¼‰"""
        try:
            with open(file_path, "rb") as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            self.log(f"ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {file_path} - {e}", "ERROR")
            return ""
    
    def load_processed_files_db(self) -> Dict:
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿"""
        try:
            if os.path.exists(self.processed_files_db):
                with open(self.processed_files_db, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception as e:
            self.log(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«DBèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
        
        return {"processed_files": {}, "last_update": None}
    
    def save_processed_files_db(self, db: Dict):
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        try:
            db["last_update"] = datetime.now().isoformat()
            with open(self.processed_files_db, "w", encoding="utf-8") as f:
                json.dump(db, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.log(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
    
    def scan_pdf_files(self) -> List[Dict]:
        """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ãƒ»å¤‰æ›´æ¤œå‡º"""
        pdf_files = []
        
        if not os.path.exists(self.pdf_folder):
            self.log(f"PDFãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.pdf_folder}", "ERROR")
            return pdf_files
        
        for file_name in os.listdir(self.pdf_folder):
            if file_name.endswith(".pdf"):
                file_path = os.path.join(self.pdf_folder, file_name)
                file_hash = self.get_file_hash(file_path)
                file_size = os.path.getsize(file_path)
                modified_time = os.path.getmtime(file_path)
                
                pdf_files.append({
                    "name": file_name,
                    "path": file_path,
                    "hash": file_hash,
                    "size": file_size,
                    "modified": modified_time
                })
        
        self.log(f"PDFãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {len(pdf_files)}å€‹")
        return pdf_files
    
    def determine_processing_strategy(self) -> Dict:
        """å‡¦ç†æˆ¦ç•¥æ±ºå®šï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆ vs å¢—åˆ†å‡¦ç†ï¼‰"""
        strategy = {
            "mode": "clean",  # "clean" or "incremental"
            "all_files": [],
            "new_files": [],
            "changed_files": [],
            "total_to_process": 0
        }
        
        pdf_files = self.scan_pdf_files()
        strategy["all_files"] = pdf_files
        
        # å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰
        if self.force_clean:
            strategy["mode"] = "clean"
            strategy["total_to_process"] = len(pdf_files)
            self.log("ğŸ”„ å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰")
            return strategy
        
        # æ—¢å­˜çµæœãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        results_exist = os.path.exists(self.extraction_results)
        
        if not results_exist:
            strategy["mode"] = "clean"
            strategy["total_to_process"] = len(pdf_files)
            self.log("ğŸ“‹ æ—¢å­˜çµæœãªã— - ã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆ")
            return strategy
        
        # å¢—åˆ†å‡¦ç†ãƒã‚§ãƒƒã‚¯
        processed_db = self.load_processed_files_db()
        processed_files = processed_db.get("processed_files", {})
        
        for pdf_file in pdf_files:
            file_name = pdf_file["name"]
            current_hash = pdf_file["hash"]
            
            if file_name not in processed_files:
                strategy["new_files"].append(pdf_file)
                self.log(f"ğŸ†• æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}")
            else:
                stored_hash = processed_files[file_name].get("hash", "")
                if current_hash != stored_hash:
                    strategy["changed_files"].append(pdf_file)
                    self.log(f"ğŸ”„ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}")
        
        # å¢—åˆ†å‡¦ç†ã®å¯å¦åˆ¤å®š
        files_to_process = strategy["new_files"] + strategy["changed_files"]
        strategy["total_to_process"] = len(files_to_process)
        
        if files_to_process:
            strategy["mode"] = "incremental"
            self.log(f"ğŸ“ˆ å¢—åˆ†å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {len(files_to_process)}ãƒ•ã‚¡ã‚¤ãƒ«")
        else:
            self.log("âœ… å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãªã— - åˆ†æã®ã¿å®Ÿè¡Œ")
        
        return strategy
    
    def backup_existing_results(self):
        """æ—¢å­˜çµæœã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        files_to_backup = [
            self.extraction_results,
            self.multi_vocab_results,
            self.vocab_results
        ]
        
        for file_name in files_to_backup:
            if os.path.exists(file_name):
                backup_name = f"{file_name.split('.')[0]}_backup_{backup_timestamp}.json"
                subprocess.run(["cp", file_name, backup_name], check=True)
                self.log(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_name}")
    
    def run_clean_ocr_extraction(self):
        """ã‚¯ãƒªãƒ¼ãƒ³OCRæŠ½å‡º"""
        self.log("ğŸ”„ ã‚¯ãƒªãƒ¼ãƒ³OCRæŠ½å‡ºé–‹å§‹")
        
        try:
            # æ—¢å­˜çµæœå‰Šé™¤
            for result_file in [self.extraction_results, self.multi_vocab_results, self.vocab_results]:
                if os.path.exists(result_file):
                    os.remove(result_file)
                    self.log(f"ğŸ—‘ï¸  å‰Šé™¤: {result_file}")
            
            # OCRå®Ÿè¡Œ
            result = subprocess.run(
                [sys.executable, "pdf_text_extractor.py"],
                capture_output=True,
                text=True,
                check=True
            )
            
            self.log("âœ… ã‚¯ãƒªãƒ¼ãƒ³OCRæŠ½å‡ºå®Œäº†")
            return True
            
        except subprocess.CalledProcessError as e:
            self.log(f"âŒ OCRæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            if e.stderr:
                self.log(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}", "ERROR")
            return False
    
    def run_vocabulary_analysis(self):
        """èªå½™åˆ†æå®Ÿè¡Œ"""
        self.log("ğŸ“š èªå½™åˆ†æé–‹å§‹")
        
        try:
            # Target 1900åˆ†æ
            subprocess.run([sys.executable, "vocabulary_analyzer.py"], check=True)
            self.log("âœ… Target 1900åˆ†æå®Œäº†")
            
            # è¤‡æ•°å˜èªå¸³åˆ†æ
            subprocess.run([sys.executable, "vocabulary_analyzer_multi.py"], check=True)
            self.log("âœ… è¤‡æ•°å˜èªå¸³åˆ†æå®Œäº†")
            
            return True
            
        except subprocess.CalledProcessError as e:
            self.log(f"âŒ èªå½™åˆ†æã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return False
    
    def update_streamlit_data(self):
        """Streamlitãƒ‡ãƒ¼ã‚¿æ›´æ–°"""
        try:
            data_processor_path = "utils/data_processor.py"
            if os.path.exists(data_processor_path):
                subprocess.run([sys.executable, data_processor_path], check=True)
                self.log("âœ… Streamlitãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†")
            else:
                self.log("âš ï¸  data_processor.pyæœªç™ºè¦‹ - ã‚¹ã‚­ãƒƒãƒ—", "WARNING")
        except Exception as e:
            self.log(f"âš ï¸  Streamlitãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
    
    def update_processed_files_db(self, pdf_files: List[Dict]):
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«DBæ›´æ–°"""
        processed_db = self.load_processed_files_db()
        
        for pdf_file in pdf_files:
            processed_db["processed_files"][pdf_file["name"]] = {
                "hash": pdf_file["hash"],
                "size": pdf_file["size"],
                "modified": pdf_file["modified"],
                "processed_at": datetime.now().isoformat()
            }
        
        self.save_processed_files_db(processed_db)
        self.log(f"ğŸ’¾ å‡¦ç†æ¸ˆã¿DBæ›´æ–°: {len(pdf_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    def send_notification(self, title: str, message: str):
        """ã‚·ã‚¹ãƒ†ãƒ é€šçŸ¥é€ä¿¡"""
        try:
            if platform.system() == "Darwin":  # macOS
                script = f'display notification "{message}" with title "{title}" sound name "Glass"'
                subprocess.run(["osascript", "-e", script], check=True)
                
                # Terminalã‚’å‰é¢ã«
                subprocess.run([
                    "osascript", "-e", 
                    'tell application "Terminal" to activate'
                ], check=True)
                
        except Exception as e:
            self.log(f"âš ï¸  é€šçŸ¥é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
    
    def generate_completion_summary(self) -> Dict:
        """å‡¦ç†å®Œäº†ã‚µãƒãƒªãƒ¼"""
        end_time = datetime.now()
        duration = end_time - self.start_time
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±åé›†
        results_info = {}
        for file_name in [self.extraction_results, self.multi_vocab_results, self.vocab_results]:
            if os.path.exists(file_name):
                file_size = os.path.getsize(file_name)
                results_info[file_name] = {
                    "exists": True,
                    "size_mb": round(file_size / (1024 * 1024), 2),
                    "modified": datetime.fromtimestamp(os.path.getmtime(file_name)).isoformat()
                }
            else:
                results_info[file_name] = {"exists": False}
        
        summary = {
            "completion_time": end_time.isoformat(),
            "duration": str(duration),
            "mode": "clean" if self.force_clean else "auto",
            "pdf_count": len(self.scan_pdf_files()),
            "generated_files": results_info,
            "log_file": self.log_file
        }
        
        with open("processing_completion_summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        return summary
    
    def run_complete_processing(self):
        """å®Œå…¨å‡¦ç†å®Ÿè¡Œ"""
        try:
            self.log("ğŸš€ ã‚¹ãƒãƒ¼ãƒˆOCRå‡¦ç†é–‹å§‹")
            
            # å‡¦ç†æˆ¦ç•¥æ±ºå®š
            strategy = self.determine_processing_strategy()
            total_steps = 4
            
            self.update_progress(1, total_steps, "æˆ¦ç•¥æ±ºå®šå®Œäº†", f"ãƒ¢ãƒ¼ãƒ‰: {strategy['mode']}")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            self.backup_existing_results()
            
            # OCRå‡¦ç†
            if strategy["mode"] == "clean" or strategy["total_to_process"] > 0:
                self.update_progress(2, total_steps, "OCRå‡¦ç†å®Ÿè¡Œä¸­", f"{strategy['total_to_process']}ãƒ•ã‚¡ã‚¤ãƒ«")
                
                if not self.run_clean_ocr_extraction():
                    raise Exception("OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
                # å‡¦ç†æ¸ˆã¿DBæ›´æ–°
                self.update_processed_files_db(strategy["all_files"])
            else:
                self.update_progress(2, total_steps, "OCRå‡¦ç†ã‚¹ã‚­ãƒƒãƒ—", "å¤‰æ›´ãªã—")
            
            # èªå½™åˆ†æ
            self.update_progress(3, total_steps, "èªå½™åˆ†æå®Ÿè¡Œä¸­")
            if not self.run_vocabulary_analysis():
                raise Exception("èªå½™åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # Streamlitãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.update_progress(4, total_steps, "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°ä¸­")
            self.update_streamlit_data()
            
            # å®Œäº†å‡¦ç†
            summary = self.generate_completion_summary()
            
            # æˆåŠŸé€šçŸ¥
            duration_str = str(summary["duration"]).split(".")[0]
            success_message = f"OCRãƒ»èªå½™åˆ†æå®Œäº†ï¼\nå‡¦ç†æ™‚é–“: {duration_str}\nPDF: {summary['pdf_count']}å€‹"
            
            self.log("ğŸ‰ å…¨å‡¦ç†å®Œäº†!")
            self.log(f"ğŸ“Š å‡¦ç†æ™‚é–“: {summary['duration']}")
            self.send_notification("OCRå‡¦ç†å®Œäº†", success_message)
            
            return True
            
        except Exception as e:
            error_message = f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.log(f"âŒ {error_message}", "ERROR")
            self.send_notification("OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼", error_message)
            return False

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ã‚¹ãƒãƒ¼ãƒˆOCRå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--clean", action="store_true", help="å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆ")
    args = parser.parse_args()
    
    processor = SmartOCRProcessor(force_clean=args.clean)
    success = processor.run_complete_processing()
    
    if success:
        print("\nâœ… å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        print("ğŸ“Š çµæœãƒ•ã‚¡ã‚¤ãƒ«:")
        print("   - extraction_results_pure_english.json")
        print("   - multi_vocabulary_analysis_report.json")
        print("   - processing_completion_summary.json")
    else:
        print("\nâŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        print("ğŸ“‹ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: smart_processing.log")

if __name__ == "__main__":
    main()